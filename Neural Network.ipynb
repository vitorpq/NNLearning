{
 "metadata": {
  "name": "",
  "signature": "sha256:48f47eaf14ff7cdde9e7217e10901226d70eb87a77b3ac3554a490d2331c9740"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Based on http://neuralnetworksanddeeplearning.com/chap2.html\n",
      "and Andrew Ng ML Course from Coursera\n",
      "\n",
      "$(x)^{10}$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"perceptron.jpg\" width=\"50%\"/>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Install MathJax to use $Latex$ locally\n",
      "\n",
      "```python\n",
      "from IPython.external.mathjax import install_mathjax\n",
      "install_mathjax()```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fazer um neuron\n",
      "Feedforward\n",
      "Tenho as entradas e os pesos."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inputs = [np.array([[0], [0]]),np.array([[0], [1]]),np.array([[1], [0]]),np.array([[1], [1]])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bias = np.array([[1],[1],[1],[1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Weights\n",
      "w = np.array([20, 20])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sigmoid(z):\n",
      "    ''' Sigmoid activation function '''\n",
      "    return 1.0/(1.0+np.exp(-z))\n",
      "# Vectorize the function\n",
      "sigmoid_vec = np.vectorize(sigmoid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "z = np.dot(w, inputs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sigmoid_vec(z)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "array([[ 0.5],\n",
        "       [ 1. ],\n",
        "       [ 1. ],\n",
        "       [ 1. ]])"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def feedforward(a, w):\n",
      "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
      "        a = sigmoid_vec(np.dot(w, a))\n",
      "        return a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feedforward(inputs, w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "array([[ 0.5],\n",
        "       [ 1. ],\n",
        "       [ 1. ],\n",
        "       [ 1. ]])"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# NN com 3 camadas"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"Escrita.png\" width=\"50%\"/>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## FeedForward"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Tamanho dos Layers\n",
      "sizes = [2, 2, 1]\n",
      "num_layers = len(sizes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Weights created with Easy Neurons\n",
      "# [[-3.43327, -3.59466],[-3.47137, -3.55708]] / [[-6.94198, -7.28447]]\n",
      "weights = [np.array([[-3.43327, -3.59466],[-3.47137, -3.55708]]), np.array([[-6.94198, -7.28447]])]\n",
      "# Biases\n",
      "# [[4.55499, 4.75544]] / [[5.69759]]\n",
      "biases = [np.array([[4.55499, 4.75544]]), np.array([[5.69759]])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Fazer o calculo da saida de cada camada\n",
      "output = [] # Keep the output for each training sample\n",
      "for inpu in inputs: # C\u00e1lculo para cada Training sample\n",
      "    activation = inpu\n",
      "    #output = [activation]\n",
      "    #zs = []\n",
      "    ### Feedforward calculation\n",
      "    # Calculate each training sample output\n",
      "    for b, w in zip(biases, weights):\n",
      "        a = sigmoid_vec(np.dot(w, activation) + b)\n",
      "    output.append(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "[array([[ 0.99665717]]),\n",
        " array([[ 0.16982331]]),\n",
        " array([[ 0.22367277]]),\n",
        " array([[ 0.00019764]])]"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Network Training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Backpropagation happens from backward. It derives the Cost Function according to the weights and finds the weights changes."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Backprop Steps__\n",
      "1. Training sample\n",
      "2. Set $\\Delta$ to zero\n",
      "3. Iterate through training set $1:m$\n",
      "4. Perform feedforward and calculate Activations ($a_{l}$) for each Layer\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "#import bigfloat as bf\n",
      "#bigfloat.exp(5000,bigfloat.precision(100))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Tools\n",
      "def sigmoid(z):\n",
      "    ''' Sigmoid activation function '''\n",
      "    return 1.0/(1.0 + np.exp(-z))\n",
      "# Vectorize the function\n",
      "sigmoid_vec = np.vectorize(sigmoid)\n",
      "\n",
      "def cost_derivative(output_activations, y):\n",
      "    return (output_activations - y)\n",
      "\n",
      "def sigmoid_prime(z):\n",
      "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
      "    return sigmoid(z)*(1-sigmoid(z))\n",
      "\n",
      "sigmoid_prime_vec = np.vectorize(sigmoid_prime)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Backprop function\n",
      "def backprop(x, y, weights, biases): # Entradas: Training sample\n",
      "    # No c\u00f3digo do site n\u00e3o entra os weights e biases pois \u00e9 uma classe que recebe estes com o SELF\n",
      "    nabla_b = [np.zeros(b.shape) for b in biases]\n",
      "    nabla_w = [np.zeros(w.shape) for w in weights]\n",
      "    # feedforward\n",
      "    # feedforward\n",
      "    activation = x\n",
      "    activations = [x] # list to store all the activations, layer by layer\n",
      "    zs = [] # list to store all the z vectors, layer by layer\n",
      "    for b, w in zip(biases, weights):\n",
      "        z = np.dot(w, activation)+b\n",
      "        zs.append(z)\n",
      "        activation = sigmoid_vec(z)\n",
      "        activations.append(activation)\n",
      "        # backward pass\n",
      "    delta = cost_derivative(activations[-1], y) * sigmoid_prime_vec(zs[-1])\n",
      "    nabla_b[-1] = delta\n",
      "    nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
      "    # Note that the variable l in the loop below is used a little\n",
      "    # differently to the notation in Chapter 2 of the book.  Here,\n",
      "    # l = 1 means the last layer of neurons, l = 2 is the\n",
      "    # second-last layer, and so on.  It's a renumbering of the\n",
      "    # scheme in the book, used here to take advantage of the fact\n",
      "    # that Python can use negative indices in lists.\n",
      "    for l in xrange(2, num_layers):\n",
      "        z = zs[-l]\n",
      "        spv = sigmoid_prime_vec(z)\n",
      "        delta = np.dot(weights[-l+1].transpose(), delta) * spv\n",
      "        nabla_b[-l] = delta\n",
      "        nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
      "    return (nabla_b, nabla_w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def update_weights(mini_batch, eta, weights, biases):\n",
      "    nabla_b = [np.zeros(b.shape) for b in biases]\n",
      "    nabla_w = [np.zeros(w.shape) for w in weights]\n",
      "    for x, y in mini_batch:\n",
      "        delta_nabla_b, delta_nabla_w = backprop(x, y, weights, biases)\n",
      "        nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
      "        nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
      "        weights = [w-(eta/len(mini_batch))*nw \n",
      "                            for w, nw in zip(weights, nabla_w)]\n",
      "        biases = [b-(eta/len(mini_batch))*nb \n",
      "                           for b, nb in zip(biases, nabla_b)]\n",
      "    return (weights, biases)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluation(inputs, weights, biases):\n",
      "    output = [] # Keep the output for each training sample\n",
      "    for inpu in inputs: # C\u00e1lculo para cada Training sample\n",
      "        activation = inpu\n",
      "        for b, w in zip(biases, weights):\n",
      "            activation = sigmoid_vec(np.dot(w, activation) + b)\n",
      "        output.append(activation)\n",
      "    return output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Inputs and Targets\n",
      "inputs = [np.array([[0], [0]]),np.array([[0], [1]]),np.array([[1], [0]]),np.array([[1], [1]])]\n",
      "target = [np.array([0]), np.array([0]), np.array([0]), np.array([1])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Network Architecture\n",
      "sizes = [2, 2, 1]\n",
      "num_layers = len(sizes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Random initialization\n",
      "weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
      "biases = [np.random.randn(y, 1) for y in sizes[1:]] # Biases weights"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Driksel says that $\\eta$ (learning rate) must be between $0.01 \\leq \\eta \\leq 0.9$, but Nielsen uses\n",
      "$\\eta = 3.0$ in his book."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Definitions and accessory variables\n",
      "w = weights\n",
      "b = biases\n",
      "saida = []\n",
      "mini_batch = zip(inputs, target)\n",
      "eta = 5.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run epochs for training\n",
      "for j in xrange(2000): # epochs\n",
      "    [w, b] = update_weights(mini_batch, eta, w, b)\n",
      "print evaluation(inputs, w, b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[array([[ 0.00060206]]), array([[ 0.00841434]]), array([[ 0.01016986]]), array([[ 0.97985896]])]\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Improving learning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use Cross-entropy cost function and Regularization (Weight Decay)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Onde muda em rela\u00e7\u00e3o ao m\u00e9todo anterior?\n",
      "1. Backprop\n",
      "2. F\u00f3rmulas de update dos weights"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Test AND problem with Cross-Entropy and QuadraticCost"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import network2\n",
      "from sklearn import datasets\n",
      "% pylab 'qt4'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "u\"'qt4'\"",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-66-3fd2e09cb00e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetwork2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu\"pylab 'qt4'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2203\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2204\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2205\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2207\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2124\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2125\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2126\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2127\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/site-packages/IPython/core/magics/pylab.pyc\u001b[0m in \u001b[0;36mpylab\u001b[1;34m(self, line)\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/site-packages/IPython/core/magics/pylab.pyc\u001b[0m in \u001b[0;36mpylab\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mimport_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_import_all\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclobbered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_pylab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimport_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimport_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Populating the interactive namespace from numpy and matplotlib\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36menable_pylab\u001b[1;34m(self, gui, import_all, welcome_message)\u001b[0m\n\u001b[0;32m   2980\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylabtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimport_pylab\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2982\u001b[1;33m         \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2984\u001b[0m         \u001b[1;31m# We want to prevent the loading of pylab to pollute the user's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36menable_matplotlib\u001b[1;34m(self, gui)\u001b[0m\n\u001b[0;32m   2929\u001b[0m         \"\"\"\n\u001b[0;32m   2930\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2931\u001b[1;33m         \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[1;34m(gui, gui_select)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;31m# select backend based on requested gui\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackends\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;31m# We need to read the backend from the original data structure, *not*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: u\"'qt4'\""
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris = datasets.load_iris()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'module' object has no attribute 'plot'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-64-3b27607b9a65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'plot'"
       ]
      }
     ],
     "prompt_number": 64
    }
   ],
   "metadata": {}
  }
 ]
}